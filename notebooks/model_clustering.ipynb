{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Sklearn Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will use Latent Dirichlet Allocation (LDA) for clustering.\n",
    "# The goal is to reduce the 23 game categories (genres) to meaningful clusters.\n",
    "# LDA will analyze the textual data (features, description, genre) to identify hidden topics,\n",
    "# which will serve as the main clusters for these game genres ('category')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "# import nltk\n",
    "import pyLDAvis.lda_model\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset to show all rows\n",
    "\n",
    "pd.reset_option('display.max_rows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Set up Game Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_df = pd.read_csv('../data/meta_cleaned.csv')\n",
    "\n",
    "lda_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine columns into a single text field for LDA\n",
    "\n",
    "lda_df = lda_df[['parent_asin', 'features', 'description', 'category']]\n",
    "\n",
    "lda_df['lda_text'] = lda_df['features'] + ' ' + lda_df['description'] + ' ' + lda_df['category']\n",
    "\n",
    "lda_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lda_df.iloc[2351]['features'], '\\n')\n",
    "print(lda_df.iloc[2351]['description'], '\\n')\n",
    "print(lda_df.iloc[2351]['category'], '\\n')\n",
    "print('LDA STRING >>>', lda_df.iloc[2351]['lda_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the concatenated column for LDA input\n",
    "\n",
    "lda_df = lda_df[['parent_asin', 'lda_text']]\n",
    "\n",
    "print(lda_df.sample()['lda_text'].iloc[0])\n",
    "\n",
    "lda_df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase Conversion\n",
    "\n",
    "lda_df['lda_text'] = lda_df['lda_text'].str.lower()\n",
    "\n",
    "print(lda_df.sample()['lda_text'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation, numbers, special characters, symbols, etc.\n",
    "\n",
    "def keep_only_text(text):\n",
    "    cleaned_text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)  # Spaces\n",
    "    return cleaned_text\n",
    "\n",
    "lda_df['lda_text'] = lda_df['lda_text'].apply(keep_only_text)\n",
    "\n",
    "print(lda_df.iloc[2351]['lda_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Lemmatization using SpaCy\n",
    "\n",
    "# Load english model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return ' '.join([token.lemma_ for token in doc])\n",
    "\n",
    "lda_df['lda_text'] = lda_df['lda_text'].apply(lemmatize_text)\n",
    "\n",
    "print(lda_df.iloc[2351]['lda_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Stopwords using NLTK\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# Load stopword list\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Add custom stopwords\n",
    "custom_stopwords = ['game', 'new', 'player', 'play', 'include', 'world', 'one', 'take', \n",
    "                    'feature', 'mode', 'use', 'und', 'die', 'sie', 'der', 'experience', \n",
    "                    'original', 'nintendo', 'switch', 'lego', 'character', 'gameplay', \n",
    "                    'get', 'edition', 'set', 'unique', 'nba', 'make', 'super', 'time', \n",
    "                    'ultimate', 'epic', 'system', 'version', 'call', 'good', 'friend', \n",
    "                    'like', 'create', 'way', 'content', 'year', 'fun', 'series', 'first', \n",
    "                    'creed', 'wwe', 'duty', 'resident', 'assassin', 'dragon', 'pack', \n",
    "                    'street', 'fighter', 'classic', 'three', 'gb', 'move']\n",
    "\n",
    "stop_words.update(custom_stopwords)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    tokens = text.split()\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "\n",
    "lda_df['lda_text'] = lda_df['lda_text'].apply(remove_stopwords)\n",
    "\n",
    "print(lda_df.iloc[2351]['lda_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Bag-of-Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "corpus = lda_df['lda_text']\n",
    "\n",
    "# Fit and transform the text data\n",
    "bow_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "print('Vocabulary:', vectorizer.get_feature_names_out())\n",
    "print('Sparse Matrix Shape:', bow_matrix.shape)\n",
    "print('Sparse Matrix Sample:', bow_matrix.toarray()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of topics\n",
    "n_topics = 4\n",
    "\n",
    "# Initialize LDA model\n",
    "lda_model = LatentDirichletAllocation(n_components = n_topics, random_state = 42)\n",
    "\n",
    "# Fit LDA model to BoW matrix\n",
    "lda_model.fit(bow_matrix)\n",
    "\n",
    "print('LDA model fitted with >>>', n_topics, '<<< topics!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the word distributions for each topic\n",
    "topic_word_distributions = lda_model.components_ \n",
    "\n",
    "# Get the word list from the vectorizer\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Get top words for each topic\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic #{topic_idx + 1}:\")\n",
    "        # Get indices of the top words\n",
    "        top_word_indices = topic.argsort()[-n_top_words:][::-1]\n",
    "        top_words = [feature_names[i] for i in top_word_indices]\n",
    "        # Print top words\n",
    "        print(' '.join(top_words), '\\n')\n",
    "\n",
    "print_top_words(lda_model, vocabulary, n_top_words = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA: 4 Topics proven best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic #1: Combat-Focused Gameplay\n",
    "# Represents games centered on battles, warfare, and multiplayer combat.\n",
    "# Includes FPS, tactical shooters, and MOBAs, with a focus on defeating enemies and teamwork.\n",
    "\n",
    "# Topic #2: Engaging Simulated Worlds\n",
    "# Encompasses games involving sports, racing, and team challenges, \n",
    "# as well as simulation games like life management or vehicle-based gameplay.\n",
    "\n",
    "# Topic #3: Action and Tactical Strategy\n",
    "# Covers games with action-packed combat, exploration, and abilities, \n",
    "# while also including strategic games where planning and tactical execution are essential.\n",
    "\n",
    "# Topic #4: Open Worlds and Discovery\n",
    "# Reflects games with a focus on story-driven adventures, open-world exploration, \n",
    "# life simulation, survival, or sandbox-style gameplay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize LDA with t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the document-topic distribution matrix\n",
    "doc_topic_matrix = lda_model.transform(bow_matrix)\n",
    "\n",
    "# Reduce dimensionality using t-SNE\n",
    "tsne = TSNE(n_components = 2, random_state = 42, perplexity = 30)\n",
    "tsne_results = tsne.fit_transform(doc_topic_matrix)\n",
    "\n",
    "# Identify the dominant topic for each document\n",
    "dominant_topics = np.argmax(doc_topic_matrix, axis = 1)\n",
    "\n",
    "# Get the unique topics present in the data\n",
    "unique_topics = np.unique(dominant_topics)\n",
    "\n",
    "# Create a custom colormap\n",
    "topic_colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "custom_palette = ListedColormap(topic_colors[:len(unique_topics)])\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize = (7, 5))\n",
    "\n",
    "scatter = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], \n",
    "                       c = dominant_topics, cmap = custom_palette, alpha = 0.7)\n",
    "\n",
    "handles = [plt.Line2D([0], [0], marker='o', color = topic_colors[i], markersize = 10, linestyle = '') \n",
    "           for i in unique_topics]\n",
    "\n",
    "labels = [f\"Topic {i + 1}\" for i in unique_topics]\n",
    "\n",
    "plt.legend(handles, labels, title = 'Topics', loc = 'best')\n",
    "plt.title('Clustered Video Game Genres')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize LDA with pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert LDA model outputs for pyLDAvis\n",
    "doc_lengths = np.array(bow_matrix.sum(axis = 1)).flatten()\n",
    "term_frequency = np.array(bow_matrix.sum(axis = 0)).flatten()\n",
    "\n",
    "# Normalize topic-term and document-topic distributions\n",
    "topic_term_dists = lda_model.components_ / lda_model.components_.sum(axis = 1)[:, np.newaxis]\n",
    "doc_topic_dists = lda_model.transform(bow_matrix)\n",
    "\n",
    "# Prepare visualization data\n",
    "lda_vis_data = pyLDAvis.prepare(\n",
    "    topic_term_dists = topic_term_dists,\n",
    "    doc_topic_dists = doc_topic_dists,\n",
    "    doc_lengths = doc_lengths,\n",
    "    vocab = vocabulary,\n",
    "    term_frequency = term_frequency,\n",
    "    n_jobs = 1  # Disable parallelism\n",
    ")\n",
    "\n",
    "# Display the visualization\n",
    "pyLDAvis.display(lda_vis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Topic Information to Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic Dictionary\n",
    "topics = {0: 'Combat-Focused Gameplay', \n",
    "          1: 'Engaging Simulated Worlds', \n",
    "          2: 'Action and Tactical Strategy', \n",
    "          3: 'Open Worlds and Discovery'}\n",
    "\n",
    "# Get the topic probabilities for each game\n",
    "topic_probabilities = lda_model.transform(bow_matrix)\n",
    "\n",
    "# # Assign each game to the most likely topic\n",
    "assigned_topics = topic_probabilities.argmax(axis = 1)\n",
    "\n",
    "# Add the topic assignment to the dataset\n",
    "lda_df['topic'] = [topics[num] for num in assigned_topics]\n",
    "\n",
    "lda_df.drop('lda_text', axis = 1, inplace = True)\n",
    "\n",
    "lda_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save LDA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset index\n",
    "\n",
    "lda_df.reset_index(inplace = True, drop = True)\n",
    "\n",
    "# Save the dataset with LDA results\n",
    "\n",
    "lda_df.to_csv('../data/meta_clustered.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
